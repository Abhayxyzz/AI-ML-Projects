{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset"
      ],
      "metadata": {
        "id": "k65MsFqsmD-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N8zBu8gUldxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca8aec8-5dfe-40db-b194-7fd61c0cf231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "8jQgeinDnm7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "m3IqZ_N-nmNf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "LHSYuX1qog4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Image Preprocessing"
      ],
      "metadata": {
        "id": "AZ1hql0ezhe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Fruit_vegetable_Recognition/train',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = None,\n",
        "    color_mode = 'rgb',\n",
        "    batch_size = 32,\n",
        "    image_size = (64,64),\n",
        "    shuffle = True,\n",
        "    seed = None,\n",
        "    validation_split = None,\n",
        "    subset = None,\n",
        "    interpolation = 'bilinear',\n",
        "    follow_links = False,\n",
        "    crop_to_aspect_ratio = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT61d9VnolY1",
        "outputId": "ac07a9f3-1fb9-49a2-96ec-21d8db02364d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3115 files belonging to 36 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Validation Image Preprocessing"
      ],
      "metadata": {
        "id": "T6pmooE2znzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Fruit_vegetable_Recognition/validation',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = None,\n",
        "    color_mode = 'rgb',\n",
        "    batch_size = 32,\n",
        "    image_size = (64,64),\n",
        "    shuffle = True,\n",
        "    seed = None,\n",
        "    validation_split = None,\n",
        "    subset = None,\n",
        "    interpolation = 'bilinear',\n",
        "    follow_links = False,\n",
        "    crop_to_aspect_ratio = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhp96wJkymUy",
        "outputId": "236e0b72-dc5b-4388-a677-22d67ce250a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 351 files belonging to 36 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Model\n"
      ],
      "metadata": {
        "id": "Flnj2Gm3PnVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "iGZyEs2nPtVJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building Convolutional Layer"
      ],
      "metadata": {
        "id": "3n_LS-J4RX44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu', input_shape=[64,64,3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "metadata": {
        "id": "HqFph-VNRiRH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "metadata": {
        "id": "HblYJ4ywTOEz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.5)) #To avoid overfitting"
      ],
      "metadata": {
        "id": "dxV_KcVtTry_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "YPp-iMxRUaEM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
      ],
      "metadata": {
        "id": "l2YRaeY6Umyx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output Layer\n",
        "cnn.add(tf.keras.layers.Dense(units=36,activation='softmax')) #We've 36 classes"
      ],
      "metadata": {
        "id": "fUrA_c_TXEgS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compiling and Training Phase"
      ],
      "metadata": {
        "id": "z34AB475flTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PvKNOlnafn7e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history= cnn.fit(x=training_set, validation_data=validation_set,epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VZU1JNRgma3",
        "outputId": "f8cd7762-8341-44e7-80ae-8abe732277be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "98/98 [==============================] - 720s 7s/step - loss: 9.7868 - accuracy: 0.0427 - val_loss: 3.5243 - val_accuracy: 0.0912\n",
            "Epoch 2/30\n",
            "98/98 [==============================] - 123s 1s/step - loss: 4.7212 - accuracy: 0.0671 - val_loss: 3.1371 - val_accuracy: 0.1823\n",
            "Epoch 3/30\n",
            "98/98 [==============================] - 116s 1s/step - loss: 4.0642 - accuracy: 0.1143 - val_loss: 3.1276 - val_accuracy: 0.2479\n",
            "Epoch 4/30\n",
            "98/98 [==============================] - 120s 1s/step - loss: 4.7112 - accuracy: 0.1525 - val_loss: 2.9944 - val_accuracy: 0.2536\n",
            "Epoch 5/30\n",
            "98/98 [==============================] - 113s 1s/step - loss: 3.5309 - accuracy: 0.2016 - val_loss: 2.4829 - val_accuracy: 0.3704\n",
            "Epoch 6/30\n",
            "98/98 [==============================] - 112s 1s/step - loss: 3.4956 - accuracy: 0.2607 - val_loss: 2.2595 - val_accuracy: 0.4815\n",
            "Epoch 7/30\n",
            "98/98 [==============================] - 110s 1s/step - loss: 3.3040 - accuracy: 0.2892 - val_loss: 1.8897 - val_accuracy: 0.6040\n",
            "Epoch 8/30\n",
            "98/98 [==============================] - 126s 1s/step - loss: 3.2901 - accuracy: 0.3660 - val_loss: 6.8026 - val_accuracy: 0.3105\n",
            "Epoch 9/30\n",
            "98/98 [==============================] - 120s 1s/step - loss: 2.8068 - accuracy: 0.4199 - val_loss: 1.6570 - val_accuracy: 0.6467\n",
            "Epoch 10/30\n",
            "98/98 [==============================] - 111s 1s/step - loss: 2.2943 - accuracy: 0.4822 - val_loss: 1.5066 - val_accuracy: 0.7009\n",
            "Epoch 11/30\n",
            "98/98 [==============================] - 109s 1s/step - loss: 2.4379 - accuracy: 0.5140 - val_loss: 2.6453 - val_accuracy: 0.5613\n",
            "Epoch 12/30\n",
            "98/98 [==============================] - 118s 1s/step - loss: 2.4489 - accuracy: 0.5570 - val_loss: 1.3144 - val_accuracy: 0.7607\n",
            "Epoch 13/30\n",
            "98/98 [==============================] - 127s 1s/step - loss: 1.9146 - accuracy: 0.5888 - val_loss: 1.4035 - val_accuracy: 0.7607\n",
            "Epoch 14/30\n",
            "98/98 [==============================] - 118s 1s/step - loss: 1.8186 - accuracy: 0.6292 - val_loss: 1.4942 - val_accuracy: 0.7578\n",
            "Epoch 15/30\n",
            "98/98 [==============================] - 118s 1s/step - loss: 1.5420 - accuracy: 0.6655 - val_loss: 1.4700 - val_accuracy: 0.7293\n",
            "Epoch 16/30\n",
            "98/98 [==============================] - 118s 1s/step - loss: 1.4058 - accuracy: 0.6854 - val_loss: 1.1117 - val_accuracy: 0.8148\n",
            "Epoch 17/30\n",
            "98/98 [==============================] - 118s 1s/step - loss: 1.3076 - accuracy: 0.7043 - val_loss: 1.2970 - val_accuracy: 0.8120\n",
            "Epoch 18/30\n",
            "98/98 [==============================] - 123s 1s/step - loss: 1.2728 - accuracy: 0.7323 - val_loss: 1.0818 - val_accuracy: 0.8718\n",
            "Epoch 19/30\n",
            "98/98 [==============================] - 108s 1s/step - loss: 1.1959 - accuracy: 0.7464 - val_loss: 1.0636 - val_accuracy: 0.8433\n",
            "Epoch 20/30\n",
            "98/98 [==============================] - 118s 1s/step - loss: 1.1957 - accuracy: 0.7631 - val_loss: 1.2893 - val_accuracy: 0.7977\n",
            "Epoch 21/30\n",
            "98/98 [==============================] - 117s 1s/step - loss: 1.2130 - accuracy: 0.7695 - val_loss: 0.9077 - val_accuracy: 0.9259\n",
            "Epoch 22/30\n",
            "98/98 [==============================] - 118s 1s/step - loss: 1.0926 - accuracy: 0.7807 - val_loss: 1.3404 - val_accuracy: 0.8490\n",
            "Epoch 23/30\n",
            "98/98 [==============================] - 108s 1s/step - loss: 1.1118 - accuracy: 0.7942 - val_loss: 0.9588 - val_accuracy: 0.8718\n",
            "Epoch 24/30\n",
            "98/98 [==============================] - 109s 1s/step - loss: 1.0479 - accuracy: 0.8055 - val_loss: 1.3089 - val_accuracy: 0.8405\n",
            "Epoch 25/30\n",
            "98/98 [==============================] - 108s 1s/step - loss: 1.0017 - accuracy: 0.8173 - val_loss: 1.3200 - val_accuracy: 0.8832\n",
            "Epoch 26/30\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.9778 - accuracy: 0.8193 - val_loss: 1.2761 - val_accuracy: 0.8775\n",
            "Epoch 27/30\n",
            "98/98 [==============================] - 127s 1s/step - loss: 0.9793 - accuracy: 0.8199 - val_loss: 1.1210 - val_accuracy: 0.9145\n",
            "Epoch 28/30\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.9979 - accuracy: 0.8273 - val_loss: 1.0490 - val_accuracy: 0.9288\n",
            "Epoch 29/30\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.9761 - accuracy: 0.8427 - val_loss: 1.1868 - val_accuracy: 0.9259\n",
            "Epoch 30/30\n",
            "98/98 [==============================] - 109s 1s/step - loss: 0.9073 - accuracy: 0.8414 - val_loss: 2.3096 - val_accuracy: 0.7721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving Model"
      ],
      "metadata": {
        "id": "ZkKh8OdI2OCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.save('trained.model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFU9kKl912D9",
        "outputId": "8d6e397e-d370-48c1-aa99-85fc08692143"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_history.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udry28ja2-GV",
        "outputId": "a1018c2f-64c8-49bb-eee7-3fe024206e56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [9.786832809448242,\n",
              "  4.721169471740723,\n",
              "  4.0642266273498535,\n",
              "  4.711242198944092,\n",
              "  3.5308616161346436,\n",
              "  3.4956119060516357,\n",
              "  3.3039817810058594,\n",
              "  3.2900688648223877,\n",
              "  2.8068349361419678,\n",
              "  2.2942938804626465,\n",
              "  2.437925338745117,\n",
              "  2.4488613605499268,\n",
              "  1.9145570993423462,\n",
              "  1.8185635805130005,\n",
              "  1.5419847965240479,\n",
              "  1.40584397315979,\n",
              "  1.3076002597808838,\n",
              "  1.2727962732315063,\n",
              "  1.195899248123169,\n",
              "  1.195658802986145,\n",
              "  1.212955117225647,\n",
              "  1.0925966501235962,\n",
              "  1.111799716949463,\n",
              "  1.0479260683059692,\n",
              "  1.0017304420471191,\n",
              "  0.9778048396110535,\n",
              "  0.9792599678039551,\n",
              "  0.9978635311126709,\n",
              "  0.9760644435882568,\n",
              "  0.907341718673706],\n",
              " 'accuracy': [0.04269662871956825,\n",
              "  0.06709470599889755,\n",
              "  0.11428571492433548,\n",
              "  0.15248796343803406,\n",
              "  0.20160514116287231,\n",
              "  0.2606741487979889,\n",
              "  0.2892455756664276,\n",
              "  0.3659711182117462,\n",
              "  0.4199036955833435,\n",
              "  0.48218297958374023,\n",
              "  0.5139647126197815,\n",
              "  0.5569823384284973,\n",
              "  0.5887640714645386,\n",
              "  0.6292135119438171,\n",
              "  0.6654895544052124,\n",
              "  0.6853932738304138,\n",
              "  0.7043338418006897,\n",
              "  0.7322632670402527,\n",
              "  0.7463884353637695,\n",
              "  0.7630818486213684,\n",
              "  0.7695024013519287,\n",
              "  0.780738353729248,\n",
              "  0.7942215204238892,\n",
              "  0.8054574728012085,\n",
              "  0.8173354864120483,\n",
              "  0.8192616105079651,\n",
              "  0.8199036717414856,\n",
              "  0.8272873163223267,\n",
              "  0.8426966071128845,\n",
              "  0.8414125442504883],\n",
              " 'val_loss': [3.5243358612060547,\n",
              "  3.1370880603790283,\n",
              "  3.1276371479034424,\n",
              "  2.9944233894348145,\n",
              "  2.4829201698303223,\n",
              "  2.259507656097412,\n",
              "  1.8896896839141846,\n",
              "  6.802582740783691,\n",
              "  1.6570227146148682,\n",
              "  1.5065611600875854,\n",
              "  2.6453123092651367,\n",
              "  1.3143502473831177,\n",
              "  1.4034919738769531,\n",
              "  1.494162678718567,\n",
              "  1.4700030088424683,\n",
              "  1.1116801500320435,\n",
              "  1.2969905138015747,\n",
              "  1.0817586183547974,\n",
              "  1.0635956525802612,\n",
              "  1.2893296480178833,\n",
              "  0.9077330231666565,\n",
              "  1.3404462337493896,\n",
              "  0.9588128924369812,\n",
              "  1.3089299201965332,\n",
              "  1.319985032081604,\n",
              "  1.2760999202728271,\n",
              "  1.1209924221038818,\n",
              "  1.0490210056304932,\n",
              "  1.1867510080337524,\n",
              "  2.309612989425659],\n",
              " 'val_accuracy': [0.09116809070110321,\n",
              "  0.18233618140220642,\n",
              "  0.24786324799060822,\n",
              "  0.25356125831604004,\n",
              "  0.37037035822868347,\n",
              "  0.48148149251937866,\n",
              "  0.6039885878562927,\n",
              "  0.3105413019657135,\n",
              "  0.6467236280441284,\n",
              "  0.7008547186851501,\n",
              "  0.561253547668457,\n",
              "  0.7606837749481201,\n",
              "  0.7606837749481201,\n",
              "  0.7578347325325012,\n",
              "  0.7293447256088257,\n",
              "  0.8148148059844971,\n",
              "  0.811965823173523,\n",
              "  0.8717948794364929,\n",
              "  0.8433048725128174,\n",
              "  0.7977207899093628,\n",
              "  0.9259259104728699,\n",
              "  0.8490028381347656,\n",
              "  0.8717948794364929,\n",
              "  0.8404558300971985,\n",
              "  0.8831908702850342,\n",
              "  0.8774929046630859,\n",
              "  0.9145299196243286,\n",
              "  0.9287749528884888,\n",
              "  0.9259259104728699,\n",
              "  0.7720797657966614]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recording History\n",
        "import json\n",
        "with open('training_hist.json','w') as f:\n",
        "  json.dump(training_history.history,f)"
      ],
      "metadata": {
        "id": "TMJjKHwg3LkB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpjC83Y24JfW",
        "outputId": "cd881471-b8e9-4727-e11f-49dffc7cd0a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculating Accuracy of Model Achieved on Validation Set"
      ],
      "metadata": {
        "id": "sgAT_Z8jHl6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation set Accuracy: {} %\".format(training_history.history['val_accuracy'][-2]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhU2vTaiHw8d",
        "outputId": "aefc4a10-90f3-4be4-decb-c19fd8262e62"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set Accuracy: 92.59259104728699 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbPhXcuw4RX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}